{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cf9dde-8bb9-40e1-916d-ea392c6f65ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7c72f28-f5ea-4209-9b2e-7785fae90047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Dense, Input, Flatten,\\\n",
    "Conv2DTranspose, BatchNormalization, LeakyReLU, Reshape\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2a16e0-2820-4ff8-bf12-5089cec9e996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3571d5e8-73e9-4cce-bf71-6bb5ce62e5e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d8f1379-6746-4665-9877-9115db36b24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f2ad2be-3b25-4a56-867d-fc17972db7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availibility-\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpu_devices:\n",
    "    # Get number of available GPUs-\n",
    "    num_gpus = len(tf.config.list_physical_devices('GPU'))\n",
    "    print(f\"number of GPUs available = {num_gpus}\")\n",
    "    \n",
    "    print(f\"GPU: {gpu_devices}\")\n",
    "    details = tf.config.experimental.get_device_details(gpu_devices[0])\n",
    "    print(f\"GPU details: {details.get('device_name', 'Unknown GPU')}\")\n",
    "else:\n",
    "    print(\"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189fcc42-e3d3-4fdd-987a-fe5fa84aad3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e468864-aab8-4659-bdf1-551d12b5f137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1d3c0fe-103f-4c2f-9c26-5c2cc37bab6f",
   "metadata": {},
   "source": [
    "### Data preprocessing and cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba5d0e31-7d55-4d45-a1a7-7fd3ec6c0d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e83b8f4-70c0-40ab-a91a-7084874565d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset-\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9217855-c2c1-430b-8f71-d18168f3257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.keras.backend.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1af92592-57a7-48e3-9578-0fa3e29e757c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "input_shape to be used: (28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\ninput_shape to be used: {input_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63136a05-7496-4275-84fb-fbd915dba6c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f43638ef-4ff2-4526-8a49-ea2068dce697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify hyper-parameters-\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c53393-21b6-48c0-9e84-56e78f4ea0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "289489cd-071b-49ab-b8c2-f30f819ac2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datasets to floating point types-\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c0aa23c-3b8f-42cc-bca9-1a8071bd0746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default the image data consists of integers between 0 and 255 for each pixel channel. Neural networks\n",
    "# work best when each input is inside the range â€“1 to 1, so we need to divide by 255.\n",
    "\n",
    "# Normalize the training and testing datasets-\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133e5a84-92a0-40b5-a2d2-7b54709ef95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors/target to binary class matrices or one-hot encoded values-\n",
    "# y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e2fe1e6-e917-42f4-a7e3-52357e1a5ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimensions of training and testing sets are:\n",
      "X_train.shape: (60000, 28, 28, 1), y_train.shape: (60000,)\n",
      "X_test.shape: (10000, 28, 28, 1), y_test.shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDimensions of training and testing sets are:\")\n",
    "print(f\"X_train.shape: {X_train.shape}, y_train.shape: {y_train.shape}\")\n",
    "print(f\"X_test.shape: {X_test.shape}, y_test.shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea2f94c-1905-46d6-ad28-d24382d641b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2662e50-ec85-497d-b845-6b434ee4f91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF datasets-\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(60000).batch(128)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(X_test).shuffle(10000).batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b92c0a1-61dd-455c-b839-6edaa0ce60ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eb5718-2132-41a8-ace5-fcb7c0d80dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "74348af8-b586-4e41-ad3f-71f66b91f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Model):\n",
    "    def __init__(self, latent_space = 3):\n",
    "        super(Encoder, self).__init__()\n",
    "            \n",
    "        self.latent_space = latent_space\n",
    "        \n",
    "        self.conv1 = Conv2D(\n",
    "            filters = 32, kernel_size = 3,\n",
    "            strides = (2, 2), activation = None\n",
    "        )\n",
    "        \n",
    "        self.conv2 = Conv2D(\n",
    "            filters = 64, kernel_size = 3,\n",
    "            strides = (2, 2), activation = None\n",
    "        )\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        \n",
    "        # self.dense = Dense(units = self.latent_space + self.latent_space, activation = None)\n",
    "        \n",
    "        \n",
    "    def call(self, x):\n",
    "        x = tf.keras.activations.relu(self.conv1(x))\n",
    "        x = tf.keras.activations.relu(self.conv2(x))\n",
    "        x = self.flatten(x)\n",
    "        # print(f\"flattened shape: {x.shape}\")\n",
    "        # flattened shape: (None, 2304)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2425e96-7e0f-47f2-af96-79001db7cd14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0909f920-04da-49ae-83bb-4a36781d9c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(latent_space = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8757f6de-20ef-41db-8ef3-024ae8ea5218",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train[:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3e98fe30-2ef8-4ecf-ae62-02636bcbf9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_enc = encoder(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e2719870-cec3-429f-ad12-dacf5722fca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 28, 28, 1), TensorShape([3, 2304]), 1568)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X_enc.shape, 7 * 7 * 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a6e388-dae4-4d78-9da8-d85a8c92c993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a8e92e9f-38b9-4cad-ba19-35c53dcd0410",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(Model):\n",
    "    def __init__(self, latent_space = 3):\n",
    "        super(Decoder, self).__init__()\n",
    "            \n",
    "        self.latent_space = latent_space\n",
    "        \n",
    "        self.dense = Dense(units = 7 * 7 * 32, activation = None)\n",
    "        self.reshape = Reshape(target_shape = (7, 7, 32))\n",
    "        \n",
    "        self.conv2d_tran = Conv2DTranspose(\n",
    "            filters = 64, kernel_size = 3,\n",
    "            strides = 2, padding = 'same',\n",
    "            activation = None\n",
    "        )\n",
    "        \n",
    "        self.conv2d_tran2 = Conv2DTranspose(\n",
    "            filters = 32, kernel_size = 3,\n",
    "            strides = 2, padding = 'same',\n",
    "            activation = None\n",
    "        )\n",
    "        \n",
    "        self.conv2d_output = Conv2DTranspose(\n",
    "            filters = 1, kernel_size = 3,\n",
    "            strides = 1, padding = 'same'\n",
    "        )\n",
    "       \n",
    "    \n",
    "    def call(self, x):\n",
    "        x = tf.keras.activations.relu(self.dense(x))\n",
    "        x = self.reshape(x)\n",
    "        x = tf.keras.activations.relu(self.conv2d_tran(x))\n",
    "        x = tf.keras.activations.relu(self.conv2d_tran2(x))\n",
    "        # x = tf.keras.activations.sigmoid(self.conv2d_output(x))\n",
    "        x = self.conv2d_output(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bb5320-3380-45df-b9ad-4cf3fbddcad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "69f41e27-e9fe-45de-813f-9d7ee35a9fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"\n",
    "    Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\n",
    "    \"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b78d1c9-ecf8-41fe-8cae-a14932c58aac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71ba465-60eb-490b-9974-cd20e826575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.shape, log_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b54d15b2-4510-4173-ab8d-bfe904194cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Sampling()([mu, log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09028c0f-f0f7-4e25-ad8a-852cc1922b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 3])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8b4919-f9b9-447f-8d90-2b25079a0535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f7710621-4c27-4c6a-9e7a-36ec9b9b8cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "048458e8-1457-4c87-8561-c554d6d028a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_recon = decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2ed7cf4c-1b22-4091-88b1-3a4e23ae184e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([3, 28, 28, 1]), (3, 28, 28, 1), TensorShape([3, 2304]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_recon.shape, X.shape, X_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59231b6e-dc06-461f-a745-b2b6e90146b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514f5c99-9ec8-4e24-aecb-0dd80125ba8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "478ea6f8-64b3-4d19-8b03-5f6825bd2006",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(Model):\n",
    "    def __init__(self, latent_space = 3):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.latent_space = latent_space\n",
    "        \n",
    "        self.encoder = Encoder(latent_space = self.latent_space)\n",
    "        self.decoder = Decoder()\n",
    "        \n",
    "        # Define fully-connected layers for computing mean & log variance-\n",
    "        self.mu = Dense(units = self.latent_space, activation = None)\n",
    "        self.log_var = Dense(units = self.latent_space, activation = None)\n",
    "        \n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.encoder(x)\n",
    "        # print(f\"x.shape: {x.shape}\")\n",
    "        # TensorShape([batch_size, 2304])\n",
    "        \n",
    "        mu = self.mu(x)\n",
    "        log_var = self.log_var(x)\n",
    "        z = Sampling()([mu, log_var])\n",
    "        '''\n",
    "        print(f\"mu.shape: {mu.shape}, log_var.shape: {log_var.shape}\"\n",
    "              f\" & z.shape: {z.shape}\")\n",
    "        # mu.shape: (batch_size, 3), log_var.shape: (batch_size, 3) & z.shape: (batch_size, 3)\n",
    "        '''\n",
    "        x = self.decoder(z)\n",
    "        return x, mu, log_var\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7c4cb3-7a41-46e2-b48d-b7bd01c021ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0aa7129f-1429-4718-814d-86aad73536e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(latent_space = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef43bc9f-c967-4d76-bd74-fc3bd665fa16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dc71cb59-ae90-4304-8d52-ed51dde124bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 28, 28, 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "25c1bc3c-ee52-4519-9f8e-990f4cf9a260",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_recon, mu, log_var = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0e2704de-2b0e-49f7-9d1c-d3113ef9a08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([3, 28, 28, 1]), (3, 28, 28, 1))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_recon.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f81211fd-783a-4aa0-be6d-f938da3e4b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([3, 3]), TensorShape([3, 3]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.shape, log_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd635fa-1e3d-46eb-8d83-bdc8d87d478e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ed5a86-fe9f-43b3-845b-cd688982a558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fccfac48-d8d6-48ee-8ae2-d0e81fda19e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vae_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_4 (Encoder)          multiple                  18816     \n",
      "_________________________________________________________________\n",
      "decoder_3 (Decoder)          multiple                  43521     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             multiple                  6915      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             multiple                  6915      \n",
      "=================================================================\n",
      "Total params: 76,167\n",
      "Trainable params: 76,167\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get model summary-\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "28e305c9-4dcc-4064-ae64-07e783efd2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: (3, 3, 1, 32) has 288 parameters\n",
      "layer: (32,) has 0 parameters\n",
      "layer: (3, 3, 32, 64) has 18432 parameters\n",
      "layer: (64,) has 0 parameters\n",
      "layer: (3, 1568) has 4704 parameters\n",
      "layer: (1568,) has 0 parameters\n",
      "layer: (3, 3, 64, 32) has 18432 parameters\n",
      "layer: (64,) has 0 parameters\n",
      "layer: (3, 3, 32, 64) has 18432 parameters\n",
      "layer: (32,) has 0 parameters\n",
      "layer: (3, 3, 1, 32) has 288 parameters\n",
      "layer: (1,) has 0 parameters\n",
      "layer: (2304, 3) has 6912 parameters\n",
      "layer: (3,) has 0 parameters\n",
      "layer: (2304, 3) has 6912 parameters\n",
      "layer: (3,) has 0 parameters\n"
     ]
    }
   ],
   "source": [
    "# Count layer-wise number of trainable parameters-\n",
    "tot_params = 0\n",
    "\n",
    "for layer in model.trainable_variables:\n",
    "# for layer in model.trainable_weights:\n",
    "    loc_params = tf.math.count_nonzero(layer, axis = None).numpy()\n",
    "    tot_params += loc_params\n",
    "    print(f\"layer: {layer.shape} has {loc_params} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c913b482-9085-4a06-8ed4-056f24936c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE has 74400 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "print(f\"VAE has {tot_params} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441066e1-35a6-4a7f-8abc-4848b29c80cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06dfb40-612d-4e51-91d1-66a7053936e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4da71e-feed-427e-aca0-35eb3dc64f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c47ee5-7414-4538-b313-b3b48f3cd11c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ab62be26-0b8d-44a8-b0fd-50b99e3d0f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an optimizer-\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31f271f-aa98-4392-9180-2833ea329229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996b13aa-f870-40e8-a879-0e2ede3f6830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "10e9262f-b4a9-4406-af8c-816960d56f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_reconstruction_loss(data, reconstruction):\n",
    "    # Reconstruction loss-\n",
    "    reconstruction_loss = tf.reduce_mean(\n",
    "        tf.reduce_sum(\n",
    "            # tf.keras.losses.binary_crossentropy(data, reconstruction), axis = (1, 2)\n",
    "            tf.keras.losses.mean_squared_error(data, reconstruction), axis = (1, 2)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return reconstruction_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe56c6bf-1476-4790-a8e8-f96ceaa91c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f33226b2-a136-4267-9e5c-42c61490b16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_loss = compute_reconstruction_loss(data = X, reconstruction = X_recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e9454774-0095-4058-8c18-53af90e0da32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.21383"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recon_loss.numpy()\n",
    "# 85.21383"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2a19f1-25af-4cdb-8e22-9e7d93b372bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e829b162-653c-4741-861c-7fba5a6c99f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "89113b1e-f867-4c65-a012-af1fe8e67505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kl_divergence_loss(mu, log_var):\n",
    "    kl_loss = -0.5 * (1 + log_var - tf.square(mu) - tf.exp(log_var))\n",
    "    kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis = 1))\n",
    "    \n",
    "    return kl_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bf60e4-ea04-4f69-8ccd-64632eb3febf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4d178d3c-e6b2-4e77-a852-ef8521cc5c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([3, 3]), TensorShape([3, 3]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.shape, log_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e69a9f62-2cfb-4a86-b284-181626c5ef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_loss = compute_kl_divergence_loss(mu = mu, log_var = log_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "189d5cdc-8a76-46dd-bd9d-be9073fdc3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006832113"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_loss.numpy()\n",
    "# 0.006832113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23860d3b-bcf0-4d9f-91af-dd5e18b9e2db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "70988942-9a1d-4603-9c9f-7dc0e9b3b00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_total_loss(data, reconstruction, mu, log_var, alpha = 1):\n",
    "    recon_loss = compute_reconstruction_loss(data = data, reconstruction = reconstruction)\n",
    "    kl_loss = compute_kl_divergence_loss(mu = mu, log_var = log_var)\n",
    "    \n",
    "    total_loss = (recon_loss * alpha) + kl_loss\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff30edde-1e1a-4245-9257-b258013f5ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b1488621-9f10-4773-9f3b-75d8c5e965b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_loss = compute_total_loss(\n",
    "    data = X, reconstruction = X_recon,\n",
    "    mu = mu, log_var = log_var,\n",
    "    alpha = 1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "eb2f44f3-8631-4260-a89c-8eb8c822d0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=85.22066>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fe9d70c8-4715-442b-a023-01f222be58a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.22066"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss.numpy()\n",
    "# 85.22066"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfb4396-7f00-4fab-a773-b41364629832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b8e7a2f7-efee-44d4-a1d4-38718faf60b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    total_loss = compute_total_loss(\n",
    "        data = X, reconstruction = X_recon,\n",
    "        mu = mu, log_var = log_var,\n",
    "        alpha = 1\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3f813a08-1641-44c4-bc76-bfb5e05cf9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = tape.gradient(total_loss, model.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0cfd3396-d8e4-4353-882b-4bb67fc6edaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 16)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(grads), len(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6707070-b0b2-4055-82aa-45b62db683a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bd63407-643f-433b-ae1f-8d0c5c23ed56",
   "metadata": {},
   "source": [
    "### _No gradients are computed!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1aa09304-fa7f-4a5e-9bed-2b76923b8465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for x in grads:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4681cd-bec7-401f-b4d3-a130eb26a162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a22e6f23-f301-4bb0-939f-aa26a1c71a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27acad78-fbd2-4105-9dcd-3473c57370ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9c6aee03-1dda-4888-91af-82fc1b390c01",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable: ['vae_1/encoder_4/conv2d_8/kernel:0', 'vae_1/encoder_4/conv2d_8/bias:0', 'vae_1/encoder_4/conv2d_9/kernel:0', 'vae_1/encoder_4/conv2d_9/bias:0', 'vae_1/decoder_3/dense_9/kernel:0', 'vae_1/decoder_3/dense_9/bias:0', 'vae_1/decoder_3/conv2d_transpose_9/kernel:0', 'vae_1/decoder_3/conv2d_transpose_9/bias:0', 'vae_1/decoder_3/conv2d_transpose_10/kernel:0', 'vae_1/decoder_3/conv2d_transpose_10/bias:0', 'vae_1/decoder_3/conv2d_transpose_11/kernel:0', 'vae_1/decoder_3/conv2d_transpose_11/bias:0', 'vae_1/dense_10/kernel:0', 'vae_1/dense_10/bias:0', 'vae_1/dense_11/kernel:0', 'vae_1/dense_11/bias:0'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_232/111942921.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-cpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[1;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[0;32m    639\u001b[0m       \u001b[0mRuntimeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mcalled\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcross\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mreplica\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m     \"\"\"\n\u001b[1;32m--> 641\u001b[1;33m     \u001b[0mgrads_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_empty_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    642\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-cpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\utils.py\u001b[0m in \u001b[0;36mfilter_empty_gradients\u001b[1;34m(grads_and_vars)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     raise ValueError(\"No gradients provided for any variable: %s.\" %\n\u001b[0m\u001b[0;32m     76\u001b[0m                      ([v.name for _, v in grads_and_vars],))\n\u001b[0;32m     77\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mvars_with_empty_grads\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No gradients provided for any variable: ['vae_1/encoder_4/conv2d_8/kernel:0', 'vae_1/encoder_4/conv2d_8/bias:0', 'vae_1/encoder_4/conv2d_9/kernel:0', 'vae_1/encoder_4/conv2d_9/bias:0', 'vae_1/decoder_3/dense_9/kernel:0', 'vae_1/decoder_3/dense_9/bias:0', 'vae_1/decoder_3/conv2d_transpose_9/kernel:0', 'vae_1/decoder_3/conv2d_transpose_9/bias:0', 'vae_1/decoder_3/conv2d_transpose_10/kernel:0', 'vae_1/decoder_3/conv2d_transpose_10/bias:0', 'vae_1/decoder_3/conv2d_transpose_11/kernel:0', 'vae_1/decoder_3/conv2d_transpose_11/bias:0', 'vae_1/dense_10/kernel:0', 'vae_1/dense_10/bias:0', 'vae_1/dense_11/kernel:0', 'vae_1/dense_11/bias:0']."
     ]
    }
   ],
   "source": [
    "optimizer.apply_gradients(zip(grads, model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c5a27e-0aa4-4612-aaf6-87c1eb17f2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
